#!/bin/sh
# The following lines instruct Slurm to allocate one GPU.
#SBATCH -o ./%A.out
#SBATCH -e ./%A.err
#SBATCH --partition=gpu
#SBATCH --gres=gpu:volta:2
#SBATCH -c2
#SBATCH --mem=150G
#SBATCH --time=124:00:00

# Set-up the environment.
source ${HOME}/.bashrc

# GPU
export CUDA_HOME="/usr/local/cuda-10.0"
export PATH="${CUDA_HOME}/bin:${PATH}"
export LIBRARY_PATH="${CUDA_HOME}/lib64:${LIBRARY_PATH}"
export LD_LIBRARY_PATH="${CUDA_HOME}/lib64:${LD_LIBRARY_PATH}"

source activate CIKM_MDR

CUDA_VISIBLE_DEVICES=0,1 python scripts/encode_corpus.py \
    --do_predict \
    --predict_batch_size 100 \
    --model_name roberta-base \
    --predict_file /data/TOMT/Movies/DPR/id2doc.json \
    --init_checkpoint /models/TOMT/Movies/DPR/.../checkpoint_best.pt \
    --embed_save_path /data/TOMT/Movies/DPR/index/ \
    --max_c_len 512 \
    --num_workers 20
