#!/bin/sh
# The following lines instruct Slurm to allocate one GPU.
#SBATCH -o ./%A.out
#SBATCH -e ./%A.err
#SBATCH -n1
#SBATCH --partition=gpu
#SBATCH --gres=gpu:1
#SBATCH -c2
#SBATCH --mem=64G
#SBATCH --time=10:00:00

# Set-up the environment.
source ${HOME}/.bashrc

# GPU
export CUDA_HOME="/usr/local/cuda-10.0"
export PATH="${CUDA_HOME}/bin:${PATH}"
export LIBRARY_PATH="${CUDA_HOME}/lib64:${LIBRARY_PATH}"
export LD_LIBRARY_PATH="${CUDA_HOME}/lib64:${LD_LIBRARY_PATH}"

source activate CIKM_MDR

python -u scripts/eval/eval_retrieval.py \
/data/TOMT/Movies/qas_test.json \
data/TOMT/Movies/DPR/index/movies.npy \
/data/TOMT/Movies/DPR/index/id2doc.json \
/models/TOMT/Movies/DPR/.../checkpoint_best.pt \
--batch-size 300 \
--model-name roberta-base \
--shared-encoder \
--save-pred /models/TOMT/Movies/DPR/.../predictions.json \
--topk 100

